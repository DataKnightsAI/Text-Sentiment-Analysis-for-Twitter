{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal - Data Preparation and Exploration\n",
    "<br>Group: Group 11 - Alex Fung, Patrick Osborne\n",
    "<br>Dataset: Twitter US Airline Sentiment\n",
    "<br>Dataset link: https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that we read the Tweets.csv with 'utf-8' encoding, so that we can extract the emojis properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0                                                                                             @VirginAmerica What @dhepburn said.   \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it   \n",
       "\n",
       "  tweet_coord              tweet_created tweet_location  \\\n",
       "0         NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1         NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2         NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3         NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4         NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Pacific Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_csv(\"../data/Tweets.csv\", encoding='utf-8')\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no nulls amongst the columns airline_sentiment and text, which is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['airline_sentiment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 'negativereason' has a few missing nulls, but they are null only if 'airline_sentiment' is positive or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5462"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['negativereason'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['airline_sentiment'].loc[df_tweets['negativereason'].isnull()].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remove not useful columns\n",
    "Looking at the dataframe above, we can see some columns will likely not be useful for our purposes of sentiment analysis, such timezones, number of retweets, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "                                                                                                                             text  \n",
       "0                                                                                             @VirginAmerica What @dhepburn said.  \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.  \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!  \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse  \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = df_tweets[\n",
    "    ['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence', 'airline', 'text']\n",
    "]\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Create new column 'text_cleaned'\n",
    "We create a column 'text_cleaned' that will contain the cleaned up version of 'text' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['text_cleaned'] = df_tweets['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove HTML encoding\n",
    "The text has not been cleaned, as there is some HTML encoding left in the text, such as \"&/amp;\". We will use BeautifulSoup and lxml package to remove the HTML encoding from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disappointed,UNITED did NOT feed small CHILDREN on a 5 & half hour flight\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Example of what BeautifulSoup with lxml package does \n",
    "#you may need to install lxml by 'pip install lxml' for this to work, then restart kernel\n",
    "example1 = BeautifulSoup('Disappointed,UNITED did NOT feed small CHILDREN on a 5 &amp; half hour flight', 'lxml')\n",
    "print(example1.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove HTML Encoding from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                           @VirginAmerica What @dhepburn said.\n",
       "1                                                                                      @VirginAmerica plus you've added commercials to the experience... tacky.\n",
       "2                                                                                       @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
       "3                                    @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
       "4                                                                                                       @VirginAmerica and it's a really big bad thing about it\n",
       "                                                                                  ...                                                                          \n",
       "14635                                                                                           @AmericanAir thank you we got on a different flight to Chicago.\n",
       "14636    @AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc\n",
       "14637                                                                                              @AmericanAir Please bring American Airlines to #BlackBerry10\n",
       "14638                   @AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??\n",
       "14639                @AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?\n",
       "Name: text_cleaned, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['text_cleaned'] = df_tweets['text_cleaned'].apply(lambda text: BeautifulSoup(text, 'lxml').get_text())\n",
    "df_tweets['text_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove retweets\n",
    "Retweets are denoted in 'text' column as 'RT @another_user another_user's tweet'. We should remove retweets because we need to analyze the tweets of the users, not the retweets. In this situation, retweets  provide no real value to our text exploration analysis as normally the users retweet to the airlines, so the retweets are based off the tweets from the specified airlines' Twitter PR, which are likely going to be either of neutral or positive sentiment. Removing such retweets will hopefully remove any noise that will prevent the models from classifying sentiment.\n",
    "\n",
    "In addition to removing retweets first, we will remove any remaining mentions afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_to_replace= r'RT \\@.*'\n",
    "replace_value= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Awesome! '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "example1 = 'Awesome! RT @VirginAmerica: Watch nominated films at 35,000 feet. #MeetTheFleet #Oscars http://t.co/DnStITRzWy'\n",
    "example1 = re.sub(regex_to_replace, replace_value, example1)\n",
    "example1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove retweets from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                           @VirginAmerica What @dhepburn said.\n",
       "1                                                                                      @VirginAmerica plus you've added commercials to the experience... tacky.\n",
       "2                                                                                       @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
       "3                                    @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
       "4                                                                                                       @VirginAmerica and it's a really big bad thing about it\n",
       "                                                                                  ...                                                                          \n",
       "14635                                                                                           @AmericanAir thank you we got on a different flight to Chicago.\n",
       "14636    @AmericanAir leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc\n",
       "14637                                                                                              @AmericanAir Please bring American Airlines to #BlackBerry10\n",
       "14638                   @AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??\n",
       "14639                @AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?\n",
       "Name: text_cleaned, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['text_cleaned'] = df_tweets['text_cleaned'].replace(to_replace=regex_to_replace, value=replace_value, regex=True)\n",
    "df_tweets['text_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Remove mentions\n",
    "Sometimes, users use mentions (for example, tweet mentions include @VirginAirlines, @JetBlue, etc., in other words, the airlines' handle). They normally appear in the beginning of the users' tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_to_replace = r'\\@[\\w\\d]*'\n",
    "replace_value= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Thank you for the follow'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "example1 = '@VirginAmerica Thank you for the follow'\n",
    "example1 = re.sub(regex_to_replace, replace_value, example1)\n",
    "example1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove mentions from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                       What  said.\n",
       "1                                                                                         plus you've added commercials to the experience... tacky.\n",
       "2                                                                                          I didn't today... Must mean I need to take another trip!\n",
       "3                                       it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
       "4                                                                                                          and it's a really big bad thing about it\n",
       "                                                                            ...                                                                    \n",
       "14635                                                                                            thank you we got on a different flight to Chicago.\n",
       "14636     leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc\n",
       "14637                                                                                               Please bring American Airlines to #BlackBerry10\n",
       "14638                    you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??\n",
       "14639                 we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?\n",
       "Name: text_cleaned, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['text_cleaned'] = df_tweets['text_cleaned'].replace(to_replace=regex_to_replace, value=replace_value, regex=True)\n",
    "df_tweets['text_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Remove HTTP links\n",
    "Should the user attach http links, we need to remove HTTP links from the text, since they provide no real value to our sentiment analysis as well. From what we can see in the data, they are mostly links to articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_to_replace = r'https*://[^\\s]*'\n",
    "replace_value = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@VirginAmerica when are you putting some great deals from PDX to LAS or from LAS to PDX show me your love! '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "example1 = '@VirginAmerica when are you putting some great deals from PDX to LAS or from LAS to PDX show me your love! http://t.co/enIQg0buzj'\n",
    "example1 = re.sub(regex_to_replace, replace_value, example1)\n",
    "example1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing HTTP Links from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                       What  said.\n",
       "1                                                                                         plus you've added commercials to the experience... tacky.\n",
       "2                                                                                          I didn't today... Must mean I need to take another trip!\n",
       "3                                       it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
       "4                                                                                                          and it's a really big bad thing about it\n",
       "                                                                            ...                                                                    \n",
       "14635                                                                                            thank you we got on a different flight to Chicago.\n",
       "14636     leaving over 20 minutes Late Flight. No warnings or communication until we were 15 minutes Late Flight. That's called shitty customer svc\n",
       "14637                                                                                               Please bring American Airlines to #BlackBerry10\n",
       "14638                    you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??\n",
       "14639                 we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?\n",
       "Name: text_cleaned, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['text_cleaned'] = df_tweets['text_cleaned'].replace(to_replace=regex_to_replace, value=replace_value, regex=True)\n",
    "df_tweets['text_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Extract Emojis and Emoticons\n",
    "Rather than removing emojis and emoticons, emojis and emoticons can be seen as an integral part of the Internet language. Therefore, we should extract emojis and emoticons from the text if they exist, as they may be good features for sentiment analysis for \"Internet\"-speak.\n",
    "\n",
    "Emojis are special characters which are shown as actual visual images, whereas emoticons are keyboard characters arranged in a certain format so that it represents a human-like facial expression.\n",
    "\n",
    "We will use a third-party Python library called 'emot', which provides the ability to recognize and extract both emojis and emoticons. Github can be found here: https://github.com/NeelShah18/emot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': ['ðŸ‘¨'], 'mean': [':man:'], 'location': [[14, 14]], 'flag': True}\n",
      "{'value': [':-)'], 'location': [[16, 19]], 'mean': ['Happy face smiley'], 'flag': True}\n"
     ]
    }
   ],
   "source": [
    "#Sanity check\n",
    "import emot\n",
    "text = \"I love python ðŸ‘¨ :-)\"\n",
    "print(emot.emoji(text))\n",
    "print(emot.emoticons(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hahaha ðŸ˜‚ YOU GUYS ARE AMAZING. I LOVE YOU GUYS!!!ðŸ’—\n",
      "{'value': ['ðŸ˜‚', 'ðŸ’—'], 'mean': [':face_with_tears_of_joy:', ':growing_heart:'], 'location': [[9, 9], [51, 51]], 'flag': True}\n",
      "{'value': [], 'location': [], 'mean': [], 'flag': False}\n"
     ]
    }
   ],
   "source": [
    "df_example1 = df_tweets.loc[df_tweets['tweet_id'] == 569198104806699008]\n",
    "print(df_example1['text_cleaned'].to_string(index=False))\n",
    "print(emot.emoji(df_example1['text_cleaned'].to_string(index=False)))\n",
    "print(emot.emoticons(df_example1['text_cleaned'].to_string(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  we have a hot female pilot! Sweet! DCA to SFO! :-)\n",
      "{'value': [], 'mean': [], 'location': [], 'flag': False}\n",
      "{'value': [':-)'], 'location': [[49, 52]], 'mean': ['Happy face smiley'], 'flag': True}\n"
     ]
    }
   ],
   "source": [
    "df_example2 = df_tweets.loc[df_tweets['tweet_id'] == 568890074164809728]\n",
    "print(df_example2['text_cleaned'].to_string(index=False))\n",
    "print(emot.emoji(df_example2['text_cleaned'].to_string(index=False)))\n",
    "print(emot.emoticons(df_example2['text_cleaned'].to_string(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracing Emojis and Emoticons from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will remove any emojis \n",
    "#accepts the following parameters: \n",
    "#(1) text_cleaned: roughly cleaned text in String to parse through and remove emojis\n",
    "#(2) emojis_flag: boolean created by emot.emoji(...), can be accessed by calling 'flag' key in dictionary (for more information see above)\n",
    "#(3) emojis: emojis object created by emot.emoji(...), can be accessed by calling 'value' key in dictionary (for more information see above)\n",
    "\n",
    "#returns the cleaned up text without emojis\n",
    "\n",
    "def remove_emojis(text_cleaned, emojis_flag, emojis):\n",
    "    text_cleaned_no_emojis = text_cleaned\n",
    "    \n",
    "    #if flag is True, that means there are emojis, and we need to remove them\n",
    "    if emojis_flag:\n",
    "        for i in emojis:\n",
    "            \n",
    "            #rather than use location, we will match by String and see if we can remove it, because I'm lazy af lol\n",
    "            #print(str(i))\n",
    "            text_cleaned_no_emojis = text_cleaned_no_emojis.replace(i, '')\n",
    "            \n",
    "        if text_cleaned_no_emojis == text_cleaned:\n",
    "            print('Uh...Houston, we have a problem...for the following text: ' + text_cleaned + ', for row: ' + str(i))\n",
    "            print('The following emojis were not removed: ' + str(emojis))\n",
    "        \n",
    "    \n",
    "    return text_cleaned_no_emojis  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the remove_emojis function\n",
    "#df_example_remove_emojis = df_tweets_2.loc[df_tweets_2['tweet_id'] == 569198104806699008]\n",
    "#print(df_example_remove_emojis['text_cleaned'].to_string(index=False))\n",
    "#print(type(df_example_remove_emojis['emojis'].item()))\n",
    "#print(df_example_remove_emojis['emojis'].item())\n",
    "#print(df_example_remove_emojis['emojis'].item())\n",
    "\n",
    "#text_remove_emojis = remove_emojis(df_example_remove_emojis['text_cleaned'].to_string(index=False), \n",
    "#                    df_example_remove_emojis['emojis_flag'].bool(), \n",
    "#                    df_example_remove_emojis['emojis'].item()\n",
    "#                   )\n",
    "#print(text_remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will remove any emoticons \n",
    "#accepts the following parameters: \n",
    "#(1) text_cleaned: roughly cleaned text in String to parse through and remove emoticons\n",
    "#(2) emoticons_flag: boolean created by emot.emoticons(...), can be accessed by calling 'flag' key in dictionary (for more information see above)\n",
    "#(3) emoticons: emojis object created by emot.emoticons(...), can be accessed by calling 'value' key in dictionary (for more information see above)\n",
    "\n",
    "#returns the cleaned up text without emoticons\n",
    "\n",
    "def remove_emoticons(text_cleaned, emoticons_flag, emoticons):\n",
    "    text_cleaned_no_emoticons = text_cleaned\n",
    "    \n",
    "    #if flag is True, that means there are emoticons, and we need to remove them\n",
    "    if emoticons_flag:\n",
    "        for i in emoticons:\n",
    "            \n",
    "            #rather than use location, we will match by String and see if we can remove it, because I'm lazy af lol\n",
    "            #print(str(i))\n",
    "            text_cleaned_no_emoticons = text_cleaned_no_emoticons.replace(i, '')\n",
    "            \n",
    "        if text_cleaned_no_emoticons == text_cleaned:\n",
    "            print('Uh...Houston, we have a problem...for the following text: ' + text_cleaned + ', for row: ' + str(i))\n",
    "            print('The following emojis were not removed: ' + str(emoticons))\n",
    "        \n",
    "    \n",
    "    return text_cleaned_no_emoticons  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the remove_emoticons function\n",
    "#df_example_remove_emoticons = df_tweets_2.loc[df_tweets_2['tweet_id'] == 568890074164809728]\n",
    "#print(df_example_remove_emoticons['text_cleaned'].to_string(index=False))\n",
    "#print(type(df_example_remove_emoticons['emoticons'].item()))\n",
    "#print(df_example_remove_emoticons['emoticons'].item())\n",
    "#print(df_example_remove_emoticons['emoticons'].item())\n",
    "\n",
    "#text_remove_emmoticons = remove_emoticons(df_example_remove_emoticons['text_cleaned'].to_string(index=False), \n",
    "#                    df_example_remove_emoticons['emoticons_flag'].bool(), \n",
    "#                    df_example_remove_emoticons['emoticons'].item()\n",
    "#                   )\n",
    "#print(text_remove_emmoticons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When using emot.emoticons, the output when flag=False is inconsistent, it either is \n",
    "#(a) {'value': [], 'mean': [], 'location': [], 'flag': False}, or \n",
    "#(b) {'flag': False}\n",
    "\n",
    "#df_example_not_working = df_tweets.loc[df_tweets['tweet_id'] == 570301130888122368]\n",
    "#text_example_not_working = df_example_not_working['text_cleaned'].to_string(index=False)\n",
    "#print(emot.emoji(text_example_not_working)['flag'])\n",
    "#print(emot.emoticons(text_example_not_working)[0]['flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will extract any emojis into a separate 'emojis' column,\n",
    "#while also removing said emojis from column: 'text_cleaned' \n",
    "#to form a new column: 'text_cleaned_without_emojis_emoticons'\n",
    "\n",
    "#returns dataframe with the aforementioned new columns\n",
    "\n",
    "import emot\n",
    "\n",
    "#in 'emojis_emoticons' column, it will hold the emot.emoji return dictionary (see above for examples)\n",
    "def extract_emojis(df_tweets):\n",
    "    df_tweets_2 = df_tweets\n",
    "    df_tweets_2['emojis_flag'] = ''\n",
    "    df_tweets_2['emojis'] = ''\n",
    "    df_tweets_2['emoticons_flag'] = ''\n",
    "    df_tweets_2['emoticons'] = ''\n",
    "        \n",
    "    #easier to just write out code to loop through dataframe\n",
    "    for i, row in df_tweets_2.iterrows():\n",
    "        #print(i)\n",
    "        #print(row)\n",
    "        text_cleaned = df_tweets_2.at[i, 'text_cleaned']\n",
    "        emojis = emot.emoji(text_cleaned)\n",
    "        emoticons = emot.emoticons(text_cleaned)\n",
    "        #print('EMOJIS: ' + str(emojis))\n",
    "        #print('EMOTICONS: ' + str(emoticons))\n",
    "        \n",
    "        ##When using emot.emoticons, the output when flag=False is inconsistent, it either is \n",
    "        #(a) {'value': [], 'mean': [], 'location': [], 'flag': False}, or \n",
    "        #(b) {'flag': False}\n",
    "        \n",
    "        #Therefore we have a bunch of try-except the aforementioned exception that will be raised, and set the values manually\n",
    "        try: \n",
    "            df_tweets_2.at[i, 'emojis_flag'] = emojis['flag']\n",
    "        except:\n",
    "            print('Unable to grab emojis flag at row number: ' + str(i))\n",
    "            df_tweets_2.at[i, 'emojis_flag'] = False\n",
    "            \n",
    "        try: \n",
    "             df_tweets_2.at[i, 'emojis'] = emojis['value']\n",
    "        except: \n",
    "            print('Unable to grab emojis value at row number: ' + str(i))\n",
    "            df_tweets_2.at[i, 'emojis'] = []\n",
    "            \n",
    "        try: \n",
    "            df_tweets_2.at[i, 'emoticons_flag'] = emoticons['flag']\n",
    "        except: \n",
    "            print('Unable to grab emoticons flag at row number: ' + str(i))\n",
    "            df_tweets_2.at[i, 'emoticons_flag'] = False\n",
    "            \n",
    "            \n",
    "        try: \n",
    "            df_tweets_2.at[i, 'emoticons'] = emoticons['value']\n",
    "        except: \n",
    "            print('Unable to grab emoticons value at row number: ' + str(i))\n",
    "            df_tweets_2.at[i, 'emoticons'] = []\n",
    "    \n",
    "        #afterwards, we need to remove emojis and emoticons from the\n",
    "        if df_tweets_2.at[i, 'emojis_flag'] == True:\n",
    "            df_tweets_2.at[i, 'text_cleaned_without_emojis_emoticons'] = remove_emojis(\n",
    "                text_cleaned,\n",
    "                df_tweets_2.at[i, 'emojis_flag'],\n",
    "                df_tweets_2.at[i, 'emojis']\n",
    "            )\n",
    "        \n",
    "        if df_tweets_2.at[i, 'emoticons_flag'] == True:\n",
    "            df_tweets_2.at[i, 'text_cleaned_without_emojis_emoticons'] = remove_emoticons(\n",
    "                text_cleaned,\n",
    "                df_tweets_2.at[i, 'emoticons_flag'],\n",
    "                df_tweets_2.at[i, 'emoticons']\n",
    "            )\n",
    "        \n",
    "    return df_tweets_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tweets['text_cleaned'] = df_tweets['text_cleaned'].apply(lambda text: BeautifulSoup(text, 'lxml').get_text())\n",
    "#df_tweets['text_cleaned']\n",
    "df_tweets_2 = extract_emojis(df_tweets)\n",
    "df_tweets_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check: briefly check some examples where we know emojis and emoticons do exist\n",
    "df_example1 = df_tweets_2.loc[df_tweets_2['tweet_id'] == 569198104806699008]\n",
    "print(df_example1['emojis_flag'])\n",
    "print(df_example1['emojis'])\n",
    "print(df_example1['text_cleaned'])\n",
    "print(df_example1['text_cleaned_without_emojis_emoticons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check: briefly check some examples where we know emojis and emoticons do exist\n",
    "df_example2 = df_tweets_2.loc[df_tweets_2['tweet_id'] == 568890074164809728]\n",
    "print(df_example2['emoticons_flag'])\n",
    "print(df_example2['emoticons'])\n",
    "print(df_example2['text_cleaned'])\n",
    "print(df_example2['text_cleaned_without_emojis_emoticons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Convert common internet abbreviations to proper English words\n",
    "Internet lingo also includes internet abbreviations, with particular channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Fix misspellings and contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df_tweets.groupby('airline_sentiment').airline_sentiment.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.groupby('negativereason').negativereason.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
