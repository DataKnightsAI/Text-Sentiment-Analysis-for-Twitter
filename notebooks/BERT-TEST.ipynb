{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexf\\Anaconda3\\envs\\CSML1010_OnlineSession2\\lib\\site-packages\\bert\\optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "  data = {}\n",
    "  data[\"sentence\"] = []\n",
    "  data[\"sentiment\"] = []\n",
    "  for file_path in os.listdir(directory):\n",
    "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "      data[\"sentence\"].append(f.read())\n",
    "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "  return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "  pos_df[\"polarity\"] = 1\n",
    "  neg_df[\"polarity\"] = 0\n",
    "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "  dataset = tf.keras.utils.get_file(\n",
    "      fname=\"aclImdb.tar.gz\", \n",
    "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "      extract=True)\n",
    "  \n",
    "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                       \"aclImdb\", \"train\"))\n",
    "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                      \"aclImdb\", \"test\"))\n",
    "  \n",
    "  return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 20s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = download_and_load_datasets()\n",
    "\n",
    "train = train.sample(5000)\n",
    "test = test.sample(5000)\n",
    "\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'sentence'\n",
    "LABEL_COLUMN = 'polarity'\n",
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12175    <bert.run_classifier.InputExample object at 0x...\n",
       "12907    <bert.run_classifier.InputExample object at 0x...\n",
       "16660    <bert.run_classifier.InputExample object at 0x...\n",
       "8828     <bert.run_classifier.InputExample object at 0x...\n",
       "7400     <bert.run_classifier.InputExample object at 0x...\n",
       "                               ...                        \n",
       "24500    <bert.run_classifier.InputExample object at 0x...\n",
       "23464    <bert.run_classifier.InputExample object at 0x...\n",
       "8852     <bert.run_classifier.InputExample object at 0x...\n",
       "9091     <bert.run_classifier.InputExample object at 0x...\n",
       "4864     <bert.run_classifier.InputExample object at 0x...\n",
       "Length: 5000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexf\\Anaconda3\\envs\\CSML1010_OnlineSession2\\lib\\site-packages\\bert\\run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexf\\Anaconda3\\envs\\CSML1010_OnlineSession2\\lib\\site-packages\\bert\\run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] if you haven ' t seen this yet , i say just move on , take a walk in the park , don ' t waste your time . neither the scenario nor the acting is worth your money . * spoil ##ers * - i can ' t decide which was worse : the movie itself or baldwin ' s hairs ##tyle ? ellen po ##mp ##eo ' s acting talent is very questionable i hope she can improve it over time . the storyline is just unbelievable . loose cannon american cop fighting criminals in europe on his own ? ? infamous slavic ma ##fi ##osi protected by only two hu ##nk ##s ? ? ? an emotional art teacher leading a ruthless gang [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] if you haven ' t seen this yet , i say just move on , take a walk in the park , don ' t waste your time . neither the scenario nor the acting is worth your money . * spoil ##ers * - i can ' t decide which was worse : the movie itself or baldwin ' s hairs ##tyle ? ellen po ##mp ##eo ' s acting talent is very questionable i hope she can improve it over time . the storyline is just unbelievable . loose cannon american cop fighting criminals in europe on his own ? ? infamous slavic ma ##fi ##osi protected by only two hu ##nk ##s ? ? ? an emotional art teacher leading a ruthless gang [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2065 2017 4033 1005 1056 2464 2023 2664 1010 1045 2360 2074 2693 2006 1010 2202 1037 3328 1999 1996 2380 1010 2123 1005 1056 5949 2115 2051 1012 4445 1996 11967 4496 1996 3772 2003 4276 2115 2769 1012 1008 27594 2545 1008 1011 1045 2064 1005 1056 5630 2029 2001 4788 1024 1996 3185 2993 2030 10970 1005 1055 13606 27983 1029 9155 13433 8737 8780 1005 1055 3772 5848 2003 2200 21068 1045 3246 2016 2064 5335 2009 2058 2051 1012 1996 9994 2003 2074 23653 1012 6065 8854 2137 8872 3554 12290 1999 2885 2006 2010 2219 1029 1029 14429 13838 5003 8873 20049 5123 2011 2069 2048 15876 8950 2015 1029 1029 1029 2019 6832 2396 3836 2877 1037 18101 6080 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2065 2017 4033 1005 1056 2464 2023 2664 1010 1045 2360 2074 2693 2006 1010 2202 1037 3328 1999 1996 2380 1010 2123 1005 1056 5949 2115 2051 1012 4445 1996 11967 4496 1996 3772 2003 4276 2115 2769 1012 1008 27594 2545 1008 1011 1045 2064 1005 1056 5630 2029 2001 4788 1024 1996 3185 2993 2030 10970 1005 1055 13606 27983 1029 9155 13433 8737 8780 1005 1055 3772 5848 2003 2200 21068 1045 3246 2016 2064 5335 2009 2058 2051 1012 1996 9994 2003 2074 23653 1012 6065 8854 2137 8872 3554 12290 1999 2885 2006 2010 2219 1029 1029 14429 13838 5003 8873 20049 5123 2011 2069 2048 15876 8950 2015 1029 1029 1029 2019 6832 2396 3836 2877 1037 18101 6080 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] ko ##lch ##ak is sheer entertainment . great stories and a great cast and nothing else to weigh it down . darren mc ##ga ##vin gives an energetic performance that pulls the audience along with him . simon oakland , jack grin ##nage and ruth mc ##dev ##itt give mc ##ga ##vin the kind of solid support that most leading actors can only dream of having . some excellent guest stars add colour and verve to individual episodes - erik estrada in legacy of terror , phil silver ##s in horror in the heights , antonio far ##gas in the zombie . it ' s easy to see how a boy ##hood spent watching ko ##lch ##ak drove chris carter to create the x files . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] ko ##lch ##ak is sheer entertainment . great stories and a great cast and nothing else to weigh it down . darren mc ##ga ##vin gives an energetic performance that pulls the audience along with him . simon oakland , jack grin ##nage and ruth mc ##dev ##itt give mc ##ga ##vin the kind of solid support that most leading actors can only dream of having . some excellent guest stars add colour and verve to individual episodes - erik estrada in legacy of terror , phil silver ##s in horror in the heights , antonio far ##gas in the zombie . it ' s easy to see how a boy ##hood spent watching ko ##lch ##ak drove chris carter to create the x files . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 12849 29358 4817 2003 11591 4024 1012 2307 3441 1998 1037 2307 3459 1998 2498 2842 2000 17042 2009 2091 1012 12270 11338 3654 6371 3957 2019 18114 2836 2008 8005 1996 4378 2247 2007 2032 1012 4079 9182 1010 2990 5861 27031 1998 7920 11338 24844 12474 2507 11338 3654 6371 1996 2785 1997 5024 2490 2008 2087 2877 5889 2064 2069 3959 1997 2383 1012 2070 6581 4113 3340 5587 6120 1998 29230 2000 3265 4178 1011 10240 26482 1999 8027 1997 7404 1010 6316 3165 2015 1999 5469 1999 1996 7535 1010 4980 2521 12617 1999 1996 11798 1012 2009 1005 1055 3733 2000 2156 2129 1037 2879 9021 2985 3666 12849 29358 4817 5225 3782 5708 2000 3443 1996 1060 6764 1012 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 12849 29358 4817 2003 11591 4024 1012 2307 3441 1998 1037 2307 3459 1998 2498 2842 2000 17042 2009 2091 1012 12270 11338 3654 6371 3957 2019 18114 2836 2008 8005 1996 4378 2247 2007 2032 1012 4079 9182 1010 2990 5861 27031 1998 7920 11338 24844 12474 2507 11338 3654 6371 1996 2785 1997 5024 2490 2008 2087 2877 5889 2064 2069 3959 1997 2383 1012 2070 6581 4113 3340 5587 6120 1998 29230 2000 3265 4178 1011 10240 26482 1999 8027 1997 7404 1010 6316 3165 2015 1999 5469 1999 1996 7535 1010 4980 2521 12617 1999 1996 11798 1012 2009 1005 1055 3733 2000 2156 2129 1037 2879 9021 2985 3666 12849 29358 4817 5225 3782 5708 2000 3443 1996 1060 6764 1012 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this is the best sci - fi that i have seen in my 29 years of watching sci - fi . i also believe that dark angel will become a cult favorite . the action is great but jessica alba is the best and most gorgeous star on tv today . [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this is the best sci - fi that i have seen in my 29 years of watching sci - fi . i also believe that dark angel will become a cult favorite . the action is great but jessica alba is the best and most gorgeous star on tv today . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2003 1996 2190 16596 1011 10882 2008 1045 2031 2464 1999 2026 2756 2086 1997 3666 16596 1011 10882 1012 1045 2036 2903 2008 2601 4850 2097 2468 1037 8754 5440 1012 1996 2895 2003 2307 2021 8201 18255 2003 1996 2190 1998 2087 9882 2732 2006 2694 2651 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2003 1996 2190 16596 1011 10882 2008 1045 2031 2464 1999 2026 2756 2086 1997 3666 16596 1011 10882 1012 1045 2036 2903 2008 2601 4850 2097 2468 1037 8754 5440 1012 1996 2895 2003 2307 2021 8201 18255 2003 1996 2190 1998 2087 9882 2732 2006 2694 2651 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i ' ve seen all four of the movies in this series . each one stray ##s further and further from the books . this is the worst one yet . my problem is that it does not follow the book it is titled after in any way ! the directors and producers should have named it any thing other than \" love ' s ab ##idi ##ng joy . \" the only thing about this movie that remotely resembles the book are the names of some of the characters ( willie , miss ##ie , henry , clark , scott ##ie and cookie ) . the names / ages / gender ##s of the children are wrong . the entire story line is no where [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i ' ve seen all four of the movies in this series . each one stray ##s further and further from the books . this is the worst one yet . my problem is that it does not follow the book it is titled after in any way ! the directors and producers should have named it any thing other than \" love ' s ab ##idi ##ng joy . \" the only thing about this movie that remotely resembles the book are the names of some of the characters ( willie , miss ##ie , henry , clark , scott ##ie and cookie ) . the names / ages / gender ##s of the children are wrong . the entire story line is no where [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 1005 2310 2464 2035 2176 1997 1996 5691 1999 2023 2186 1012 2169 2028 15926 2015 2582 1998 2582 2013 1996 2808 1012 2023 2003 1996 5409 2028 2664 1012 2026 3291 2003 2008 2009 2515 2025 3582 1996 2338 2009 2003 4159 2044 1999 2151 2126 999 1996 5501 1998 6443 2323 2031 2315 2009 2151 2518 2060 2084 1000 2293 1005 1055 11113 28173 3070 6569 1012 1000 1996 2069 2518 2055 2023 3185 2008 19512 12950 1996 2338 2024 1996 3415 1997 2070 1997 1996 3494 1006 9893 1010 3335 2666 1010 2888 1010 5215 1010 3660 2666 1998 17387 1007 1012 1996 3415 1013 5535 1013 5907 2015 1997 1996 2336 2024 3308 1012 1996 2972 2466 2240 2003 2053 2073 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 1005 2310 2464 2035 2176 1997 1996 5691 1999 2023 2186 1012 2169 2028 15926 2015 2582 1998 2582 2013 1996 2808 1012 2023 2003 1996 5409 2028 2664 1012 2026 3291 2003 2008 2009 2515 2025 3582 1996 2338 2009 2003 4159 2044 1999 2151 2126 999 1996 5501 1998 6443 2323 2031 2315 2009 2151 2518 2060 2084 1000 2293 1005 1055 11113 28173 3070 6569 1012 1000 1996 2069 2518 2055 2023 3185 2008 19512 12950 1996 2338 2024 1996 3415 1997 2070 1997 1996 3494 1006 9893 1010 3335 2666 1010 2888 1010 5215 1010 3660 2666 1998 17387 1007 1012 1996 3415 1013 5535 1013 5907 2015 1997 1996 2336 2024 3308 1012 1996 2972 2466 2240 2003 2053 2073 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] fascinating down ##er about a would - be male hu ##stle ##r in new york city forced to live in a condemned building with a crippled con - man . extremely bleak examination of modern - day moral and social decline , extremely well - directed by john sc ##hl ##es ##inger ( who never topped his work here ) and superb ##ly acted by jon vo ##ight and dustin hoffman . packs quite a punch overall , yet the \" fantasy \" scenes - - some of which are played for a chuckle - - are mildly int ##rus ##ive , as is the \" mod \" drug party . the relationship that develops between the two men is sentimental , yet the filmmakers are [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] fascinating down ##er about a would - be male hu ##stle ##r in new york city forced to live in a condemned building with a crippled con - man . extremely bleak examination of modern - day moral and social decline , extremely well - directed by john sc ##hl ##es ##inger ( who never topped his work here ) and superb ##ly acted by jon vo ##ight and dustin hoffman . packs quite a punch overall , yet the \" fantasy \" scenes - - some of which are played for a chuckle - - are mildly int ##rus ##ive , as is the \" mod \" drug party . the relationship that develops between the two men is sentimental , yet the filmmakers are [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 17160 2091 2121 2055 1037 2052 1011 2022 3287 15876 22516 2099 1999 2047 2259 2103 3140 2000 2444 1999 1037 10033 2311 2007 1037 24433 9530 1011 2158 1012 5186 21657 7749 1997 2715 1011 2154 7191 1998 2591 6689 1010 5186 2092 1011 2856 2011 2198 8040 7317 2229 9912 1006 2040 2196 9370 2010 2147 2182 1007 1998 21688 2135 6051 2011 6285 29536 18743 1998 24337 15107 1012 15173 3243 1037 8595 3452 1010 2664 1996 1000 5913 1000 5019 1011 1011 2070 1997 2029 2024 2209 2005 1037 15375 1011 1011 2024 19499 20014 7946 3512 1010 2004 2003 1996 1000 16913 1000 4319 2283 1012 1996 3276 2008 11791 2090 1996 2048 2273 2003 23069 1010 2664 1996 16587 2024 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 17160 2091 2121 2055 1037 2052 1011 2022 3287 15876 22516 2099 1999 2047 2259 2103 3140 2000 2444 1999 1037 10033 2311 2007 1037 24433 9530 1011 2158 1012 5186 21657 7749 1997 2715 1011 2154 7191 1998 2591 6689 1010 5186 2092 1011 2856 2011 2198 8040 7317 2229 9912 1006 2040 2196 9370 2010 2147 2182 1007 1998 21688 2135 6051 2011 6285 29536 18743 1998 24337 15107 1012 15173 3243 1037 8595 3452 1010 2664 1996 1000 5913 1000 5019 1011 1011 2070 1997 2029 2024 2209 2005 1037 15375 1011 1011 2024 19499 20014 7946 3512 1010 2004 2003 1996 1000 16913 1000 4319 2283 1012 1996 3276 2008 11791 2090 1996 2048 2273 2003 23069 1010 2664 1996 16587 2024 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] it is the best film i have seen in the last 5 years . surely , it will be in the same row with such masterpiece ##s as the platoon , apocalypse now , the doors , the dog ' s heart ( russian film ) . really , the play of the boy and his parents is so good that you can ' t even say that they \" play \" . no , they live as if it was happening to them . notice the smile on there faces when the main hero agrees to go for a walk with them . the hate and love in one piece . and the final scene ! < br / > < br / > really [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] it is the best film i have seen in the last 5 years . surely , it will be in the same row with such masterpiece ##s as the platoon , apocalypse now , the doors , the dog ' s heart ( russian film ) . really , the play of the boy and his parents is so good that you can ' t even say that they \" play \" . no , they live as if it was happening to them . notice the smile on there faces when the main hero agrees to go for a walk with them . the hate and love in one piece . and the final scene ! < br / > < br / > really [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2009 2003 1996 2190 2143 1045 2031 2464 1999 1996 2197 1019 2086 1012 7543 1010 2009 2097 2022 1999 1996 2168 5216 2007 2107 17743 2015 2004 1996 13799 1010 16976 2085 1010 1996 4303 1010 1996 3899 1005 1055 2540 1006 2845 2143 1007 1012 2428 1010 1996 2377 1997 1996 2879 1998 2010 3008 2003 2061 2204 2008 2017 2064 1005 1056 2130 2360 2008 2027 1000 2377 1000 1012 2053 1010 2027 2444 2004 2065 2009 2001 6230 2000 2068 1012 5060 1996 2868 2006 2045 5344 2043 1996 2364 5394 10217 2000 2175 2005 1037 3328 2007 2068 1012 1996 5223 1998 2293 1999 2028 3538 1012 1998 1996 2345 3496 999 1026 7987 1013 1028 1026 7987 1013 1028 2428 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2009 2003 1996 2190 2143 1045 2031 2464 1999 1996 2197 1019 2086 1012 7543 1010 2009 2097 2022 1999 1996 2168 5216 2007 2107 17743 2015 2004 1996 13799 1010 16976 2085 1010 1996 4303 1010 1996 3899 1005 1055 2540 1006 2845 2143 1007 1012 2428 1010 1996 2377 1997 1996 2879 1998 2010 3008 2003 2061 2204 2008 2017 2064 1005 1056 2130 2360 2008 2027 1000 2377 1000 1012 2053 1010 2027 2444 2004 2065 2009 2001 6230 2000 2068 1012 5060 1996 2868 2006 2045 5344 2043 1996 2364 5394 10217 2000 2175 2005 1037 3328 2007 2068 1012 1996 5223 1998 2293 1999 2028 3538 1012 1998 1996 2345 3496 999 1026 7987 1013 1028 1026 7987 1013 1028 2428 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i ' ll admit that this isn ' t a great film . it practically screams \" low - budget \" yet oddly i still found myself liking the film because although it lacked quality it ab ##ounded with energy . it was like the little engine that could and a movie merged into one ! < br / > < br / > the film takes place at a radio network and concerns some of their low - level employees - - two page boys ( one very push ##y and bra ##sh and the other one a wu ##ss ) as well as a new receptionist . all three have visions of radio star ##dom but must for now content themselves with their low [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] i ' ll admit that this isn ' t a great film . it practically screams \" low - budget \" yet oddly i still found myself liking the film because although it lacked quality it ab ##ounded with energy . it was like the little engine that could and a movie merged into one ! < br / > < br / > the film takes place at a radio network and concerns some of their low - level employees - - two page boys ( one very push ##y and bra ##sh and the other one a wu ##ss ) as well as a new receptionist . all three have visions of radio star ##dom but must for now content themselves with their low [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 1005 2222 6449 2008 2023 3475 1005 1056 1037 2307 2143 1012 2009 8134 11652 1000 2659 1011 5166 1000 2664 15056 1045 2145 2179 2870 16663 1996 2143 2138 2348 2009 10858 3737 2009 11113 26240 2007 2943 1012 2009 2001 2066 1996 2210 3194 2008 2071 1998 1037 3185 5314 2046 2028 999 1026 7987 1013 1028 1026 7987 1013 1028 1996 2143 3138 2173 2012 1037 2557 2897 1998 5936 2070 1997 2037 2659 1011 2504 5126 1011 1011 2048 3931 3337 1006 2028 2200 5245 2100 1998 11655 4095 1998 1996 2060 2028 1037 8814 4757 1007 2004 2092 2004 1037 2047 23775 1012 2035 2093 2031 12018 1997 2557 2732 9527 2021 2442 2005 2085 4180 3209 2007 2037 2659 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1045 1005 2222 6449 2008 2023 3475 1005 1056 1037 2307 2143 1012 2009 8134 11652 1000 2659 1011 5166 1000 2664 15056 1045 2145 2179 2870 16663 1996 2143 2138 2348 2009 10858 3737 2009 11113 26240 2007 2943 1012 2009 2001 2066 1996 2210 3194 2008 2071 1998 1037 3185 5314 2046 2028 999 1026 7987 1013 1028 1026 7987 1013 1028 1996 2143 3138 2173 2012 1037 2557 2897 1998 5936 2070 1997 2037 2659 1011 2504 5126 1011 1011 2048 3931 3337 1006 2028 2200 5245 2100 1998 11655 4095 1998 1996 2060 2028 1037 8814 4757 1007 2004 2092 2004 1037 2047 23775 1012 2035 2093 2031 12018 1997 2557 2732 9527 2021 2442 2005 2085 4180 3209 2007 2037 2659 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this is far the most worst film i ' ve seen this year from bollywood so far . i may not lie , my wife liked this film very much . it was not bobby de ##ol or arjun ramp ##al what made this film become unbelievable , but it was ami ##sha patel . she performs the role of a blind woman who get in trouble when she almost fall from a mountain where ( luckily for her ) the hero arjun ramp ##al comes to rescue her ( in the middle of nowhere ) . it ama ##zes me here how a blind girl is aware of danger when she is about to fall from a mountain , because she cannot see her environment [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] this is far the most worst film i ' ve seen this year from bollywood so far . i may not lie , my wife liked this film very much . it was not bobby de ##ol or arjun ramp ##al what made this film become unbelievable , but it was ami ##sha patel . she performs the role of a blind woman who get in trouble when she almost fall from a mountain where ( luckily for her ) the hero arjun ramp ##al comes to rescue her ( in the middle of nowhere ) . it ama ##zes me here how a blind girl is aware of danger when she is about to fall from a mountain , because she cannot see her environment [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2003 2521 1996 2087 5409 2143 1045 1005 2310 2464 2023 2095 2013 16046 2061 2521 1012 1045 2089 2025 4682 1010 2026 2564 4669 2023 2143 2200 2172 1012 2009 2001 2025 6173 2139 4747 2030 26024 13276 2389 2054 2081 2023 2143 2468 23653 1010 2021 2009 2001 26445 7377 20455 1012 2016 10438 1996 2535 1997 1037 6397 2450 2040 2131 1999 4390 2043 2016 2471 2991 2013 1037 3137 2073 1006 15798 2005 2014 1007 1996 5394 26024 13276 2389 3310 2000 5343 2014 1006 1999 1996 2690 1997 7880 1007 1012 2009 25933 11254 2033 2182 2129 1037 6397 2611 2003 5204 1997 5473 2043 2016 2003 2055 2000 2991 2013 1037 3137 1010 2138 2016 3685 2156 2014 4044 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2023 2003 2521 1996 2087 5409 2143 1045 1005 2310 2464 2023 2095 2013 16046 2061 2521 1012 1045 2089 2025 4682 1010 2026 2564 4669 2023 2143 2200 2172 1012 2009 2001 2025 6173 2139 4747 2030 26024 13276 2389 2054 2081 2023 2143 2468 23653 1010 2021 2009 2001 26445 7377 20455 1012 2016 10438 1996 2535 1997 1037 6397 2450 2040 2131 1999 4390 2043 2016 2471 2991 2013 1037 3137 2073 1006 15798 2005 2014 1007 1996 5394 26024 13276 2389 3310 2000 5343 2014 1006 1999 1996 2690 1997 7880 1007 1012 2009 25933 11254 2033 2182 2129 1037 6397 2611 2003 5204 1997 5473 2043 2016 2003 2055 2000 2991 2013 1037 3137 1010 2138 2016 3685 2156 2014 4044 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] . . . i normally hate pun ##s , but this seems the only appropriate summary for \" barn ##yard \" . i suspect i am not the first . and i ' m sure many , many comments focus on the id ##io ##cy of bulls with ud ##ders . it certainly bothered me right off the bat . but there ' s much more wrong with this movie than a fundamental lack of knowledge about how mammals work . < br / > < br / > personally , if i was a parent , i would be irritated by the violent turn it takes near the end in the showdown with the coyotes . ( although for me , it at least injected [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] . . . i normally hate pun ##s , but this seems the only appropriate summary for \" barn ##yard \" . i suspect i am not the first . and i ' m sure many , many comments focus on the id ##io ##cy of bulls with ud ##ders . it certainly bothered me right off the bat . but there ' s much more wrong with this movie than a fundamental lack of knowledge about how mammals work . < br / > < br / > personally , if i was a parent , i would be irritated by the violent turn it takes near the end in the showdown with the coyotes . ( although for me , it at least injected [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1012 1012 1012 1045 5373 5223 26136 2015 1010 2021 2023 3849 1996 2069 6413 12654 2005 1000 8659 14132 1000 1012 1045 8343 1045 2572 2025 1996 2034 1012 1998 1045 1005 1049 2469 2116 1010 2116 7928 3579 2006 1996 8909 3695 5666 1997 12065 2007 20904 13375 1012 2009 5121 11250 2033 2157 2125 1996 7151 1012 2021 2045 1005 1055 2172 2062 3308 2007 2023 3185 2084 1037 8050 3768 1997 3716 2055 2129 11993 2147 1012 1026 7987 1013 1028 1026 7987 1013 1028 7714 1010 2065 1045 2001 1037 6687 1010 1045 2052 2022 15560 2011 1996 6355 2735 2009 3138 2379 1996 2203 1999 1996 24419 2007 1996 26880 1012 1006 2348 2005 2033 1010 2009 2012 2560 19737 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1012 1012 1012 1045 5373 5223 26136 2015 1010 2021 2023 3849 1996 2069 6413 12654 2005 1000 8659 14132 1000 1012 1045 8343 1045 2572 2025 1996 2034 1012 1998 1045 1005 1049 2469 2116 1010 2116 7928 3579 2006 1996 8909 3695 5666 1997 12065 2007 20904 13375 1012 2009 5121 11250 2033 2157 2125 1996 7151 1012 2021 2045 1005 1055 2172 2062 3308 2007 2023 3185 2084 1037 8050 3768 1997 3716 2055 2129 11993 2147 1012 1026 7987 1013 1028 1026 7987 1013 1028 7714 1010 2065 1045 2001 1037 6687 1010 1045 2052 2022 15560 2011 1996 6355 2735 2009 3138 2379 1996 2203 1999 1996 24419 2007 1996 26880 1012 1006 2348 2005 2033 1010 2009 2012 2560 19737 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] when i saw that icon was on tv , i was surprised . i know that the first clue of where it was headed was the fact that it was on the hallmark channel - has to be said - sorry ! ! i was hopeful when i saw that ff himself was the ex ##ec producer but very quickly saw that the only real way that the tv movie and the book were similar were in the name and the character names only . the tv plot was a ho - hum to say the least but i con ##cu ##r that in and of itself , the action was worth a 3 stars . in my personal opinion , mr . sway ##ze could [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] when i saw that icon was on tv , i was surprised . i know that the first clue of where it was headed was the fact that it was on the hallmark channel - has to be said - sorry ! ! i was hopeful when i saw that ff himself was the ex ##ec producer but very quickly saw that the only real way that the tv movie and the book were similar were in the name and the character names only . the tv plot was a ho - hum to say the least but i con ##cu ##r that in and of itself , the action was worth a 3 stars . in my personal opinion , mr . sway ##ze could [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2043 1045 2387 2008 12696 2001 2006 2694 1010 1045 2001 4527 1012 1045 2113 2008 1996 2034 9789 1997 2073 2009 2001 3753 2001 1996 2755 2008 2009 2001 2006 1996 25812 3149 1011 2038 2000 2022 2056 1011 3374 999 999 1045 2001 17772 2043 1045 2387 2008 21461 2370 2001 1996 4654 8586 3135 2021 2200 2855 2387 2008 1996 2069 2613 2126 2008 1996 2694 3185 1998 1996 2338 2020 2714 2020 1999 1996 2171 1998 1996 2839 3415 2069 1012 1996 2694 5436 2001 1037 7570 1011 14910 2000 2360 1996 2560 2021 1045 9530 10841 2099 2008 1999 1998 1997 2993 1010 1996 2895 2001 4276 1037 1017 3340 1012 1999 2026 3167 5448 1010 2720 1012 17812 4371 2071 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2043 1045 2387 2008 12696 2001 2006 2694 1010 1045 2001 4527 1012 1045 2113 2008 1996 2034 9789 1997 2073 2009 2001 3753 2001 1996 2755 2008 2009 2001 2006 1996 25812 3149 1011 2038 2000 2022 2056 1011 3374 999 999 1045 2001 17772 2043 1045 2387 2008 21461 2370 2001 1996 4654 8586 3135 2021 2200 2855 2387 2008 1996 2069 2613 2126 2008 1996 2694 3185 1998 1996 2338 2020 2714 2020 1999 1996 2171 1998 1996 2839 3415 2069 1012 1996 2694 5436 2001 1037 7570 1011 14910 2000 2360 1996 2560 2021 1045 9530 10841 2099 2008 1999 1998 1997 2993 1010 1996 2895 2001 4276 1037 1017 3340 1012 1999 2026 3167 5448 1010 2720 1012 17812 4371 2071 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "# We'll set sequences to be at most 128 tokens long.\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
